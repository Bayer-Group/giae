{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we just check if the Encoder Network can correctly classify the 8 Tetris Shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from giae.se3.data import DataModule, TetrisDatasetPyG\n",
    "from giae.se3.modules import Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(hidden_dim=32, emb_dim=2, num_layers=5, layer_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = partial(TetrisDatasetPyG,\n",
    "                  rotate=False, num_elements=10000, noise_level=0.0, translation_level=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = DataModule(\n",
    "    dataset=dataset,\n",
    "    train_samples=10000,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    num_eval_samples=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = datamodule.train_dataloader(shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = encoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(2, 8, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fnc = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(encoder.parameters()) + list(lin.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0/20, Step 0/157, Loss: 2.1655, Acc: 0.1875\n",
      " Epoch: 0/20, Step 50/157, Loss: 0.6951, Acc: 0.5781\n",
      " Epoch: 0/20, Step 100/157, Loss: 0.2515, Acc: 0.8750\n",
      " Epoch: 0/20, Step 150/157, Loss: 0.4860, Acc: 0.7812\n",
      " Epoch: 1/20, Step 0/157, Loss: 0.4103, Acc: 0.7344\n",
      " Epoch: 1/20, Step 50/157, Loss: 0.1083, Acc: 0.9531\n",
      " Epoch: 1/20, Step 100/157, Loss: 1.8869, Acc: 0.2656\n",
      " Epoch: 1/20, Step 150/157, Loss: 1.3040, Acc: 0.5000\n",
      " Epoch: 2/20, Step 0/157, Loss: 1.2980, Acc: 0.6406\n",
      " Epoch: 2/20, Step 50/157, Loss: 0.6851, Acc: 0.7031\n",
      " Epoch: 2/20, Step 100/157, Loss: 0.1898, Acc: 0.8906\n",
      " Epoch: 2/20, Step 150/157, Loss: 0.0023, Acc: 1.0000\n",
      " Epoch: 3/20, Step 0/157, Loss: 0.0014, Acc: 1.0000\n",
      " Epoch: 3/20, Step 50/157, Loss: 0.0002, Acc: 1.0000\n",
      " Epoch: 3/20, Step 100/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 3/20, Step 150/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 4/20, Step 0/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 4/20, Step 50/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 4/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 4/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 5/20, Step 0/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 5/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 5/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 5/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 6/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 6/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 6/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 6/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(nepochs):\n",
    "    for j, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        shape_embed, point_embed, rot, transl_out, vout = encoder(pos=data.pos, batch=data.batch,\n",
    "                                                          batch_num_nodes=torch.bincount(data.batch), \n",
    "                                                          edge_index=data.edge_index, use_fc=True)\n",
    "        y_pred = lin(shape_embed)\n",
    "        loss = loss_fnc(y_pred, data.label.argmax(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 50 == 0:\n",
    "            acc = sum(data.label.argmax(-1) == y_pred.argmax(-1)) / len(y_pred)\n",
    "            print(f\" Epoch: {i}/{nepochs}, Step {j}/{len(train_loader)}, Loss: {loss.item():.4f}, Acc: {acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check if we create \"new\" shapes by adding some gaussian noise onto each point\n",
    "We also rotate and translate the point-cloud, as the `shape_embed` is invariant, it is not affected by it, but only the `vout` tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = partial(TetrisDatasetPyG,\n",
    "                  rotate=True, num_elements=10000, noise_level=0.01, translation_level=5.0)\n",
    "\n",
    "datamodule = DataModule(\n",
    "    dataset=dataset,\n",
    "    train_samples=10000,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    num_eval_samples=200,\n",
    ")\n",
    "train_loader = datamodule.train_dataloader(shuffle=False)\n",
    "encoder = Encoder(hidden_dim=32, emb_dim=2, num_layers=5, layer_norm=False).to(device)\n",
    "lin = torch.nn.Linear(2, 8, device=device)\n",
    "params = list(encoder.parameters()) + list(lin.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0/20, Step 0/157, Loss: 2.1845, Acc: 0.1406\n",
      " Epoch: 0/20, Step 50/157, Loss: 0.4487, Acc: 0.7812\n",
      " Epoch: 0/20, Step 100/157, Loss: 0.2378, Acc: 0.8594\n",
      " Epoch: 0/20, Step 150/157, Loss: 1.5658, Acc: 0.4531\n",
      " Epoch: 1/20, Step 0/157, Loss: 1.8023, Acc: 0.3281\n",
      " Epoch: 1/20, Step 50/157, Loss: 0.1199, Acc: 0.9375\n",
      " Epoch: 1/20, Step 100/157, Loss: 1.6783, Acc: 0.3281\n",
      " Epoch: 1/20, Step 150/157, Loss: 0.3064, Acc: 0.8125\n",
      " Epoch: 2/20, Step 0/157, Loss: 0.2008, Acc: 0.9375\n",
      " Epoch: 2/20, Step 50/157, Loss: 1.9656, Acc: 0.2500\n",
      " Epoch: 2/20, Step 100/157, Loss: 1.5561, Acc: 0.4219\n",
      " Epoch: 2/20, Step 150/157, Loss: 0.9270, Acc: 0.5938\n",
      " Epoch: 3/20, Step 0/157, Loss: 0.7318, Acc: 0.6250\n",
      " Epoch: 3/20, Step 50/157, Loss: 1.3451, Acc: 0.4844\n",
      " Epoch: 3/20, Step 100/157, Loss: 0.5641, Acc: 0.9219\n",
      " Epoch: 3/20, Step 150/157, Loss: 0.0512, Acc: 1.0000\n",
      " Epoch: 4/20, Step 0/157, Loss: 0.0189, Acc: 1.0000\n",
      " Epoch: 4/20, Step 50/157, Loss: 0.0008, Acc: 1.0000\n",
      " Epoch: 4/20, Step 100/157, Loss: 0.0006, Acc: 1.0000\n",
      " Epoch: 4/20, Step 150/157, Loss: 0.0002, Acc: 1.0000\n",
      " Epoch: 5/20, Step 0/157, Loss: 0.0002, Acc: 1.0000\n",
      " Epoch: 5/20, Step 50/157, Loss: 0.0002, Acc: 1.0000\n",
      " Epoch: 5/20, Step 100/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 5/20, Step 150/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 6/20, Step 0/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 6/20, Step 50/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 6/20, Step 100/157, Loss: 0.0002, Acc: 1.0000\n",
      " Epoch: 6/20, Step 150/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 7/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 50/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 7/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 7/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 8/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 9/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 10/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 11/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 12/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 13/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 14/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 0/157, Loss: 0.0003, Acc: 1.0000\n",
      " Epoch: 15/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 15/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 0/157, Loss: 0.0001, Acc: 1.0000\n",
      " Epoch: 16/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 16/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 17/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 18/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 0/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 50/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 100/157, Loss: 0.0000, Acc: 1.0000\n",
      " Epoch: 19/20, Step 150/157, Loss: 0.0000, Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in range(nepochs):\n",
    "    for j, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        shape_embed, point_embed, rot, transl_out, vout = encoder(pos=data.pos, batch=data.batch,\n",
    "                                                          batch_num_nodes=torch.bincount(data.batch), \n",
    "                                                          edge_index=data.edge_index, use_fc=True)\n",
    "        y_pred = lin(shape_embed)\n",
    "        loss = loss_fnc(y_pred, data.label.argmax(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if j % 50 == 0:\n",
    "            acc = sum(data.label.argmax(-1) == y_pred.argmax(-1)) / len(y_pred)\n",
    "            print(f\" Epoch: {i}/{nepochs}, Step {j}/{len(train_loader)}, Loss: {loss.item():.4f}, Acc: {acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}